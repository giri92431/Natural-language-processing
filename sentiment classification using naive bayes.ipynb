{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_review(path,positive=True):\n",
    "    label = 1 if positive else 0\n",
    "    \n",
    "    with open(path,'r') as f:\n",
    "        review_text = f.readlines()\n",
    "    \n",
    "    reviews = []\n",
    "    for text in review_text:\n",
    "        reviews.append((text,label))\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_review():\n",
    "    positive_reviews =get_review('rt-polarity.neg', positive =True)\n",
    "    negative_reviews =get_review('rt-polarity.pos', positive =False)\n",
    "    return positive_reviews ,negative_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_review , negative_reiview = extract_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_reiview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('simplistic , silly and tedious . \\n', 1),\n",
       " (\"it's so laddish and juvenile , only teenage boys could possibly find it funny . \\n\",\n",
       "  1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_review[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_Data = 5000\n",
    "Total_data =len(positive_review)\n",
    "\n",
    "tain_reviews =positive_review[:Train_Data] + negative_reiview[:Train_Data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positive_reviews = positive_review[Train_Data:Total_data]\n",
    "test_negative_reviews = negative_reiview[Train_Data:Total_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(tain_reviews):\n",
    "    word_set =set()\n",
    "    for review in tain_reviews:\n",
    "        word_set.update(review[0].split())\n",
    "        \n",
    "    return list(word_set)\n",
    "vocabulary =get_vocabulary(tain_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20728"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(review_text):\n",
    "    review_words =set(review_text.split())\n",
    "    \n",
    "    features = {}\n",
    "    for word in vocabulary:\n",
    "        features[word]= (word in review_words)\n",
    "    return  features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = nltk.classify.apply_features(extract_features,tain_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_classifier = nltk.NaiveBayesClassifier.train(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_calculator(review_text):\n",
    "    features= extract_features(review_text)\n",
    "    return train_classifier.classify(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator(\"what an amazing movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator(\"what an bad movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_reviews(test_positive_reiviews,test_negative_reviews ,sentiment_calculator):\n",
    "    positive_results = [sentiment_calculator(review[0]) for review in test_positive_reiviews]\n",
    "    negative_results = [sentiment_calculator(review[0]) for review in test_negative_reviews]\n",
    "    \n",
    "    true_positives = sum(x > 0 for x in positive_results)\n",
    "    true_negative = sum(x > 0 for x in negative_results)\n",
    "    \n",
    "    percentage_true_positive =float(true_positives)/len(positive_results)\n",
    "    percentage_true_negative =float(true_negative)/len(negative_results)\n",
    "    \n",
    "    total_acurate = true_positives + true_negative\n",
    "    total = len (positive_results) + len(negative_results)\n",
    "    \n",
    "    \n",
    "    print(\"Accuracy on positve review=\" + \"%.2f\" %(percentage_true_positive*100)+\"%\")\n",
    "    print(\"Accuracy on negative review=\" + \"%.2f\" %(percentage_true_negative*100)+\"%\")\n",
    "    print(\"overall accuracy =\" + \"%.2f\"%(total_acurate *100/total)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on positve review=80.66%\n",
      "Accuracy on negative review=21.75%\n",
      "overall accuracy =51.21%\n"
     ]
    }
   ],
   "source": [
    "classify_test_reviews(test_positive_reviews,test_negative_reviews,sentiment_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
